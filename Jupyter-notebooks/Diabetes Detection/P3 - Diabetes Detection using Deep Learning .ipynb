{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import sys \r\n",
    "import pandas as pd \r\n",
    "import numpy as np\r\n",
    "import sklearn \r\n",
    "import tensorflow.keras as keras \r\n",
    "\r\n",
    "print(\"Python: {}\".format(sys.version))\r\n",
    "print(\"Pandas: {}\".format(pd.__version__))\r\n",
    "print(\"Numpy: {}\".format(np.__version__))\r\n",
    "print(\"Sklearn: {}\".format(sklearn.__version__))\r\n",
    "print(\"Keras: {}\".format(keras.__version__))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python: 3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]\n",
      "Pandas: 1.2.4\n",
      "Numpy: 1.19.5\n",
      "Sklearn: 0.24.2\n",
      "Keras: 2.5.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "names = {'Pregnancies': 'n_pregnant', 'Glucose': 'glucose_concentration', 'BloodPressure': 'blood_pressuer (mm Hg)', \r\n",
    "         'SkinThickness': 'skin_thickness (mm)', 'Insulin': 'serum_insulin (mu U/ml)', \r\n",
    "         'DiabetesPedigreeFunction': 'pedigree_function', 'Age': 'age', 'Outcome': 'class'}\r\n",
    "df = pd.read_csv('./../diabetes.csv')\r\n",
    "df.rename(columns = names, inplace = True)\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   n_pregnant  glucose_concentration  blood_pressuer (mm Hg)  \\\n",
       "0           6                    148                      72   \n",
       "1           1                     85                      66   \n",
       "2           8                    183                      64   \n",
       "3           1                     89                      66   \n",
       "4           0                    137                      40   \n",
       "\n",
       "   skin_thickness (mm)  serum_insulin (mu U/ml)   BMI  pedigree_function  age  \\\n",
       "0                   35                        0  33.6              0.627   50   \n",
       "1                   29                        0  26.6              0.351   31   \n",
       "2                    0                        0  23.3              0.672   32   \n",
       "3                   23                       94  28.1              0.167   21   \n",
       "4                   35                      168  43.1              2.288   33   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressuer (mm Hg)</th>\n",
       "      <th>skin_thickness (mm)</th>\n",
       "      <th>serum_insulin (mu U/ml)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Describe the data we have \r\n",
    "df.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       n_pregnant  glucose_concentration  blood_pressuer (mm Hg)  \\\n",
       "count  768.000000             768.000000              768.000000   \n",
       "mean     3.845052             120.894531               69.105469   \n",
       "std      3.369578              31.972618               19.355807   \n",
       "min      0.000000               0.000000                0.000000   \n",
       "25%      1.000000              99.000000               62.000000   \n",
       "50%      3.000000             117.000000               72.000000   \n",
       "75%      6.000000             140.250000               80.000000   \n",
       "max     17.000000             199.000000              122.000000   \n",
       "\n",
       "       skin_thickness (mm)  serum_insulin (mu U/ml)         BMI  \\\n",
       "count           768.000000               768.000000  768.000000   \n",
       "mean             20.536458                79.799479   31.992578   \n",
       "std              15.952218               115.244002    7.884160   \n",
       "min               0.000000                 0.000000    0.000000   \n",
       "25%               0.000000                 0.000000   27.300000   \n",
       "50%              23.000000                30.500000   32.000000   \n",
       "75%              32.000000               127.250000   36.600000   \n",
       "max              99.000000               846.000000   67.100000   \n",
       "\n",
       "       pedigree_function         age       class  \n",
       "count         768.000000  768.000000  768.000000  \n",
       "mean            0.471876   33.240885    0.348958  \n",
       "std             0.331329   11.760232    0.476951  \n",
       "min             0.078000   21.000000    0.000000  \n",
       "25%             0.243750   24.000000    0.000000  \n",
       "50%             0.372500   29.000000    0.000000  \n",
       "75%             0.626250   41.000000    1.000000  \n",
       "max             2.420000   81.000000    1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressuer (mm Hg)</th>\n",
       "      <th>skin_thickness (mm)</th>\n",
       "      <th>serum_insulin (mu U/ml)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# We see columns such as glucose_concentration, BMI, etc. have 0 as min value. It might be because of missing datas\r\n",
    "# Checking how much data is missing \r\n",
    "columns = ['glucose_concentration', 'blood_pressuer (mm Hg)', 'skin_thickness (mm)','serum_insulin (mu U/ml)']\r\n",
    "for col in columns:\r\n",
    "    df[col].replace(0, np.NaN, inplace=True)\r\n",
    "\r\n",
    "df.describe() "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       n_pregnant  glucose_concentration  blood_pressuer (mm Hg)  \\\n",
       "count  768.000000             763.000000              733.000000   \n",
       "mean     3.845052             121.686763               72.405184   \n",
       "std      3.369578              30.535641               12.382158   \n",
       "min      0.000000              44.000000               24.000000   \n",
       "25%      1.000000              99.000000               64.000000   \n",
       "50%      3.000000             117.000000               72.000000   \n",
       "75%      6.000000             141.000000               80.000000   \n",
       "max     17.000000             199.000000              122.000000   \n",
       "\n",
       "       skin_thickness (mm)  serum_insulin (mu U/ml)         BMI  \\\n",
       "count           541.000000               394.000000  768.000000   \n",
       "mean             29.153420               155.548223   31.992578   \n",
       "std              10.476982               118.775855    7.884160   \n",
       "min               7.000000                14.000000    0.000000   \n",
       "25%              22.000000                76.250000   27.300000   \n",
       "50%              29.000000               125.000000   32.000000   \n",
       "75%              36.000000               190.000000   36.600000   \n",
       "max              99.000000               846.000000   67.100000   \n",
       "\n",
       "       pedigree_function         age       class  \n",
       "count         768.000000  768.000000  768.000000  \n",
       "mean            0.471876   33.240885    0.348958  \n",
       "std             0.331329   11.760232    0.476951  \n",
       "min             0.078000   21.000000    0.000000  \n",
       "25%             0.243750   24.000000    0.000000  \n",
       "50%             0.372500   29.000000    0.000000  \n",
       "75%             0.626250   41.000000    1.000000  \n",
       "max             2.420000   81.000000    1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressuer (mm Hg)</th>\n",
       "      <th>skin_thickness (mm)</th>\n",
       "      <th>serum_insulin (mu U/ml)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>12.382158</td>\n",
       "      <td>10.476982</td>\n",
       "      <td>118.775855</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Drop rows with missing datas \r\n",
    "df.dropna(inplace=True)\r\n",
    "\r\n",
    "df.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       n_pregnant  glucose_concentration  blood_pressuer (mm Hg)  \\\n",
       "count  393.000000             393.000000              393.000000   \n",
       "mean     3.292621             122.615776               70.646310   \n",
       "std      3.211645              30.822276               12.484668   \n",
       "min      0.000000              56.000000               24.000000   \n",
       "25%      1.000000              99.000000               62.000000   \n",
       "50%      2.000000             119.000000               70.000000   \n",
       "75%      5.000000             143.000000               78.000000   \n",
       "max     17.000000             198.000000              110.000000   \n",
       "\n",
       "       skin_thickness (mm)  serum_insulin (mu U/ml)         BMI  \\\n",
       "count           393.000000               393.000000  393.000000   \n",
       "mean             29.129771               155.885496   33.002036   \n",
       "std              10.507575               118.738199    7.214395   \n",
       "min               7.000000                14.000000    0.000000   \n",
       "25%              21.000000                77.000000   28.400000   \n",
       "50%              29.000000               125.000000   33.200000   \n",
       "75%              37.000000               190.000000   37.100000   \n",
       "max              63.000000               846.000000   67.100000   \n",
       "\n",
       "       pedigree_function         age       class  \n",
       "count         393.000000  393.000000  393.000000  \n",
       "mean            0.526120   30.839695    0.330789  \n",
       "std             0.350386   10.199903    0.471097  \n",
       "min             0.085000   21.000000    0.000000  \n",
       "25%             0.270000   23.000000    0.000000  \n",
       "50%             0.452000   27.000000    0.000000  \n",
       "75%             0.687000   36.000000    1.000000  \n",
       "max             2.420000   81.000000    1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressuer (mm Hg)</th>\n",
       "      <th>skin_thickness (mm)</th>\n",
       "      <th>serum_insulin (mu U/ml)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>393.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.292621</td>\n",
       "      <td>122.615776</td>\n",
       "      <td>70.646310</td>\n",
       "      <td>29.129771</td>\n",
       "      <td>155.885496</td>\n",
       "      <td>33.002036</td>\n",
       "      <td>0.526120</td>\n",
       "      <td>30.839695</td>\n",
       "      <td>0.330789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.211645</td>\n",
       "      <td>30.822276</td>\n",
       "      <td>12.484668</td>\n",
       "      <td>10.507575</td>\n",
       "      <td>118.738199</td>\n",
       "      <td>7.214395</td>\n",
       "      <td>0.350386</td>\n",
       "      <td>10.199903</td>\n",
       "      <td>0.471097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>37.100000</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Convert data to numpy array \r\n",
    "data = df.values\r\n",
    "print(data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(393, 9)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Split to X and Y sets \r\n",
    "X = data[:,0:-1]\r\n",
    "Y = data[:,-1].astype(int)        # We don't want our classes to be of float type "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Checking if split has been properly done \r\n",
    "print(X.shape)\r\n",
    "print(Y.shape)\r\n",
    "print(X[:5,:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(393, 8)\n",
      "(393,)\n",
      "[[1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]\n",
      " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
      "  2.600e+01]\n",
      " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
      "  5.300e+01]\n",
      " [1.000e+00 1.890e+02 6.000e+01 2.300e+01 8.460e+02 3.010e+01 3.980e-01\n",
      "  5.900e+01]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Looking at datas we observe thaat they are in a very different scales, \r\n",
    "# example n_pregnant (from 1 to 17) and serum_insulin (from 14 to 846). So we will normalize the data \r\n",
    "# Normalizing using sklearn StandardScaler  ( converts to 0 mean, unit variance)\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler = StandardScaler().fit(X)         \r\n",
    "# Creates a tranformation that when applied to any data will transform it into 0 mean unit variance distribution of X \r\n",
    "\r\n",
    "X_standardized = scaler.transform(X)       \r\n",
    "# Applying tranformation on X so that it is standardized. \r\n",
    "# We will have to apply the same transformation for any other data we will test our model with. \r\n",
    "\r\n",
    "df_Standardized = pd.DataFrame(X_standardized)\r\n",
    "\r\n",
    "df_Standardized.describe()    \r\n",
    "# To check if all values are in similar range or not also check for 0 mean and 1 standard deviation. "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  3.930000e+02  3.930000e+02  3.930000e+02  3.930000e+02  3.930000e+02   \n",
       "mean   9.943982e-17 -1.242998e-16 -1.107398e-16 -1.514197e-16  6.327989e-17   \n",
       "std    1.001275e+00  1.001275e+00  1.001275e+00  1.001275e+00  1.001275e+00   \n",
       "min   -1.026520e+00 -2.164042e+00 -3.741050e+00 -2.108762e+00 -1.196467e+00   \n",
       "25%   -7.147562e-01 -7.671685e-01 -6.934371e-01 -7.746920e-01 -6.652118e-01   \n",
       "50%   -4.029924e-01 -1.174600e-01 -5.183432e-02 -1.236597e-02 -2.604458e-01   \n",
       "75%    5.322990e-01  6.621901e-01  5.897685e-01  7.499600e-01  2.876748e-01   \n",
       "max    4.273465e+00  2.448888e+00  3.156180e+00  3.227519e+00  5.819477e+00   \n",
       "\n",
       "                  5             6             7  \n",
       "count  3.930000e+02  3.930000e+02  3.930000e+02  \n",
       "mean   1.536797e-16  1.129998e-17 -7.683986e-17  \n",
       "std    1.001275e+00  1.001275e+00  1.001275e+00  \n",
       "min   -4.580301e+00 -1.260558e+00 -9.659148e-01  \n",
       "25%   -6.387094e-01 -7.318959e-01 -7.695846e-01  \n",
       "50%    2.747517e-02 -2.118066e-01 -3.769241e-01  \n",
       "75%    5.687501e-01  4.597372e-01  5.065620e-01  \n",
       "max    4.732404e+00  5.412016e+00  4.923993e+00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.930000e+02</td>\n",
       "      <td>3.930000e+02</td>\n",
       "      <td>3.930000e+02</td>\n",
       "      <td>3.930000e+02</td>\n",
       "      <td>3.930000e+02</td>\n",
       "      <td>3.930000e+02</td>\n",
       "      <td>3.930000e+02</td>\n",
       "      <td>3.930000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.943982e-17</td>\n",
       "      <td>-1.242998e-16</td>\n",
       "      <td>-1.107398e-16</td>\n",
       "      <td>-1.514197e-16</td>\n",
       "      <td>6.327989e-17</td>\n",
       "      <td>1.536797e-16</td>\n",
       "      <td>1.129998e-17</td>\n",
       "      <td>-7.683986e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001275e+00</td>\n",
       "      <td>1.001275e+00</td>\n",
       "      <td>1.001275e+00</td>\n",
       "      <td>1.001275e+00</td>\n",
       "      <td>1.001275e+00</td>\n",
       "      <td>1.001275e+00</td>\n",
       "      <td>1.001275e+00</td>\n",
       "      <td>1.001275e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.026520e+00</td>\n",
       "      <td>-2.164042e+00</td>\n",
       "      <td>-3.741050e+00</td>\n",
       "      <td>-2.108762e+00</td>\n",
       "      <td>-1.196467e+00</td>\n",
       "      <td>-4.580301e+00</td>\n",
       "      <td>-1.260558e+00</td>\n",
       "      <td>-9.659148e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.147562e-01</td>\n",
       "      <td>-7.671685e-01</td>\n",
       "      <td>-6.934371e-01</td>\n",
       "      <td>-7.746920e-01</td>\n",
       "      <td>-6.652118e-01</td>\n",
       "      <td>-6.387094e-01</td>\n",
       "      <td>-7.318959e-01</td>\n",
       "      <td>-7.695846e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.029924e-01</td>\n",
       "      <td>-1.174600e-01</td>\n",
       "      <td>-5.183432e-02</td>\n",
       "      <td>-1.236597e-02</td>\n",
       "      <td>-2.604458e-01</td>\n",
       "      <td>2.747517e-02</td>\n",
       "      <td>-2.118066e-01</td>\n",
       "      <td>-3.769241e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.322990e-01</td>\n",
       "      <td>6.621901e-01</td>\n",
       "      <td>5.897685e-01</td>\n",
       "      <td>7.499600e-01</td>\n",
       "      <td>2.876748e-01</td>\n",
       "      <td>5.687501e-01</td>\n",
       "      <td>4.597372e-01</td>\n",
       "      <td>5.065620e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.273465e+00</td>\n",
       "      <td>2.448888e+00</td>\n",
       "      <td>3.156180e+00</td>\n",
       "      <td>3.227519e+00</td>\n",
       "      <td>5.819477e+00</td>\n",
       "      <td>4.732404e+00</td>\n",
       "      <td>5.412016e+00</td>\n",
       "      <td>4.923993e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Import necessary packages and layers \r\n",
    "from sklearn.model_selection import GridSearchCV, KFold\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense \r\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier \r\n",
    "from tensorflow.keras.optimizers import Adam"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Defining the model \r\n",
    "\r\n",
    "def create_model():\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation = 'relu'))\r\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation = 'relu'))\r\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\r\n",
    "    \r\n",
    "    # Compile the model\r\n",
    "    adam = Adam(learning_rate=0.01)\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "    \r\n",
    "model = create_model()\r\n",
    "print(model.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Create a model\r\n",
    "model = KerasClassifier(build_fn=create_model, verbose = 0)\r\n",
    "\r\n",
    "# Grid Search over batch_size and epochs \r\n",
    "batch_size = [10, 20, 40]\r\n",
    "epochs = [10, 50, 100]\r\n",
    "\r\n",
    "# Make a dictionary for grid search parameters as GridSearchCV takes dictionary as inputs \r\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\r\n",
    "\r\n",
    "# Build and fit over grid parameters\r\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(n_splits=3), verbose=10)\r\n",
    "grid_results = grid.fit(X_standardized, Y)\r\n",
    "\r\n",
    "# Summarize the result \r\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\r\n",
    "\r\n",
    "means = grid_results.cv_results_['mean_test_score']\r\n",
    "stds = grid_results.cv_results_['std_test_score']\r\n",
    "params = grid_results.cv_results_['params']\r\n",
    "\r\n",
    "for mean, std, param in zip(means, stds, params):\r\n",
    "    print(\"Mean: {0}, Standard Deviation: {1}, using {2}\".format(mean, std, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV 1/3; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/3; 1/9] END .....batch_size=10, epochs=10;, score=0.763 total time=   2.3s\n",
      "[CV 2/3; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/3; 1/9] END .....batch_size=10, epochs=10;, score=0.763 total time=   1.2s\n",
      "[CV 3/3; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/3; 1/9] END .....batch_size=10, epochs=10;, score=0.817 total time=   1.4s\n",
      "[CV 1/3; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/3; 2/9] END .....batch_size=10, epochs=50;, score=0.733 total time=   3.3s\n",
      "[CV 2/3; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/3; 2/9] END .....batch_size=10, epochs=50;, score=0.763 total time=   3.0s\n",
      "[CV 3/3; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/3; 2/9] END .....batch_size=10, epochs=50;, score=0.809 total time=   3.3s\n",
      "[CV 1/3; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/3; 3/9] END ....batch_size=10, epochs=100;, score=0.771 total time=   5.1s\n",
      "[CV 2/3; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/3; 3/9] END ....batch_size=10, epochs=100;, score=0.786 total time=   4.6s\n",
      "[CV 3/3; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/3; 3/9] END ....batch_size=10, epochs=100;, score=0.832 total time=   5.6s\n",
      "[CV 1/3; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/3; 4/9] END .....batch_size=20, epochs=10;, score=0.725 total time=   1.0s\n",
      "[CV 2/3; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/3; 4/9] END .....batch_size=20, epochs=10;, score=0.763 total time=   1.3s\n",
      "[CV 3/3; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/3; 4/9] END .....batch_size=20, epochs=10;, score=0.832 total time=   1.5s\n",
      "[CV 1/3; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/3; 5/9] END .....batch_size=20, epochs=50;, score=0.710 total time=   3.6s\n",
      "[CV 2/3; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/3; 5/9] END .....batch_size=20, epochs=50;, score=0.794 total time=   2.6s\n",
      "[CV 3/3; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/3; 5/9] END .....batch_size=20, epochs=50;, score=0.855 total time=   3.3s\n",
      "[CV 1/3; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/3; 6/9] END ....batch_size=20, epochs=100;, score=0.756 total time=   3.3s\n",
      "[CV 2/3; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/3; 6/9] END ....batch_size=20, epochs=100;, score=0.771 total time=   4.8s\n",
      "[CV 3/3; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/3; 6/9] END ....batch_size=20, epochs=100;, score=0.832 total time=   3.6s\n",
      "[CV 1/3; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/3; 7/9] END .....batch_size=40, epochs=10;, score=0.733 total time=   1.4s\n",
      "[CV 2/3; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/3; 7/9] END .....batch_size=40, epochs=10;, score=0.763 total time=   1.1s\n",
      "[CV 3/3; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/3; 7/9] END .....batch_size=40, epochs=10;, score=0.817 total time=   2.0s\n",
      "[CV 1/3; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/3; 8/9] END .....batch_size=40, epochs=50;, score=0.740 total time=   1.5s\n",
      "[CV 2/3; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/3; 8/9] END .....batch_size=40, epochs=50;, score=0.756 total time=   1.2s\n",
      "[CV 3/3; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/3; 8/9] END .....batch_size=40, epochs=50;, score=0.824 total time=   1.4s\n",
      "[CV 1/3; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/3; 9/9] END ....batch_size=40, epochs=100;, score=0.763 total time=   2.1s\n",
      "[CV 2/3; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/3; 9/9] END ....batch_size=40, epochs=100;, score=0.763 total time=   2.0s\n",
      "[CV 3/3; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 3/3; 9/9] END ....batch_size=40, epochs=100;, score=0.847 total time=   2.3s\n",
      "Best: 0.7964376409848531, using {'batch_size': 10, 'epochs': 100}\n",
      "Mean: 0.7811704874038696, Standard Deviation: 0.025189569774717948, using {'batch_size': 10, 'epochs': 10}\n",
      "Mean: 0.7684478362401327, Standard Deviation: 0.03137105174488196, using {'batch_size': 10, 'epochs': 50}\n",
      "Mean: 0.7964376409848531, Standard Deviation: 0.02594921160575286, using {'batch_size': 10, 'epochs': 100}\n",
      "Mean: 0.7735368808110555, Standard Deviation: 0.04421920515449277, using {'batch_size': 20, 'epochs': 10}\n",
      "Mean: 0.7862595518430074, Standard Deviation: 0.05945709152172618, using {'batch_size': 20, 'epochs': 50}\n",
      "Mean: 0.7862595319747925, Standard Deviation: 0.0329808610415624, using {'batch_size': 20, 'epochs': 100}\n",
      "Mean: 0.770992378393809, Standard Deviation: 0.03470275778092071, using {'batch_size': 40, 'epochs': 10}\n",
      "Mean: 0.7735369006792704, Standard Deviation: 0.03652086629950575, using {'batch_size': 40, 'epochs': 50}\n",
      "Mean: 0.7913485964139303, Standard Deviation: 0.03958358957605749, using {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Here we will grid search over learning_rate and dropout \r\n",
    "from tensorflow.keras.layers import Dropout\r\n",
    "\r\n",
    "# Define our model\r\n",
    "def create_model(learning_rate, dropout):\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation = 'relu'))\r\n",
    "    model.add(Dropout(dropout))\r\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation = 'relu'))\r\n",
    "    model.add(Dropout(dropout))\r\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\r\n",
    "    \r\n",
    "    # Compile the model\r\n",
    "    adam = Adam(learning_rate=learning_rate)\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "\r\n",
    "# Create a model\r\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=10, epochs=100, verbose = 0)\r\n",
    "\r\n",
    "# Grid Search over learning_rate and dropout \r\n",
    "learning_rate = [0.001, 0.01, 0.1]\r\n",
    "dropout = [0, 0.05, 0.1]\r\n",
    "\r\n",
    "# Make a dictionary for grid search parameters as GridSearchCV takes dictionary as inputs \r\n",
    "param_grid = dict(learning_rate=learning_rate, dropout=dropout)\r\n",
    "\r\n",
    "# Build and fit over grid parameters\r\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(n_splits=3), verbose=10)\r\n",
    "grid_results = grid.fit(X_standardized, Y)\r\n",
    "\r\n",
    "# Summarize the result \r\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\r\n",
    "\r\n",
    "means = grid_results.cv_results_['mean_test_score']\r\n",
    "stds = grid_results.cv_results_['std_test_score']\r\n",
    "params = grid_results.cv_results_['params']\r\n",
    "\r\n",
    "for mean, std, param in zip(means, stds, params):\r\n",
    "    print(\"Mean: {0}, Standard Deviation: {1}, using {2}\".format(mean, std, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV 1/3; 1/9] START dropout=0, learning_rate=0.001..............................\n",
      "[CV 1/3; 1/9] END dropout=0, learning_rate=0.001;, score=0.756 total time=   5.7s\n",
      "[CV 2/3; 1/9] START dropout=0, learning_rate=0.001..............................\n",
      "[CV 2/3; 1/9] END dropout=0, learning_rate=0.001;, score=0.756 total time=   6.0s\n",
      "[CV 3/3; 1/9] START dropout=0, learning_rate=0.001..............................\n",
      "[CV 3/3; 1/9] END dropout=0, learning_rate=0.001;, score=0.855 total time=   6.1s\n",
      "[CV 1/3; 2/9] START dropout=0, learning_rate=0.01...............................\n",
      "[CV 1/3; 2/9] END dropout=0, learning_rate=0.01;, score=0.748 total time=   7.5s\n",
      "[CV 2/3; 2/9] START dropout=0, learning_rate=0.01...............................\n",
      "[CV 2/3; 2/9] END dropout=0, learning_rate=0.01;, score=0.718 total time=   5.4s\n",
      "[CV 3/3; 2/9] START dropout=0, learning_rate=0.01...............................\n",
      "[CV 3/3; 2/9] END dropout=0, learning_rate=0.01;, score=0.802 total time=   5.0s\n",
      "[CV 1/3; 3/9] START dropout=0, learning_rate=0.1................................\n",
      "[CV 1/3; 3/9] END .dropout=0, learning_rate=0.1;, score=0.718 total time=   5.2s\n",
      "[CV 2/3; 3/9] START dropout=0, learning_rate=0.1................................\n",
      "[CV 2/3; 3/9] END .dropout=0, learning_rate=0.1;, score=0.725 total time=   5.3s\n",
      "[CV 3/3; 3/9] START dropout=0, learning_rate=0.1................................\n",
      "[CV 3/3; 3/9] END .dropout=0, learning_rate=0.1;, score=0.702 total time=   6.0s\n",
      "[CV 1/3; 4/9] START dropout=0.05, learning_rate=0.001...........................\n",
      "[CV 1/3; 4/9] END dropout=0.05, learning_rate=0.001;, score=0.771 total time=   6.9s\n",
      "[CV 2/3; 4/9] START dropout=0.05, learning_rate=0.001...........................\n",
      "[CV 2/3; 4/9] END dropout=0.05, learning_rate=0.001;, score=0.763 total time=   6.5s\n",
      "[CV 3/3; 4/9] START dropout=0.05, learning_rate=0.001...........................\n",
      "[CV 3/3; 4/9] END dropout=0.05, learning_rate=0.001;, score=0.832 total time=   7.1s\n",
      "[CV 1/3; 5/9] START dropout=0.05, learning_rate=0.01............................\n",
      "[CV 1/3; 5/9] END dropout=0.05, learning_rate=0.01;, score=0.740 total time=   6.1s\n",
      "[CV 2/3; 5/9] START dropout=0.05, learning_rate=0.01............................\n",
      "[CV 2/3; 5/9] END dropout=0.05, learning_rate=0.01;, score=0.779 total time=   6.2s\n",
      "[CV 3/3; 5/9] START dropout=0.05, learning_rate=0.01............................\n",
      "[CV 3/3; 5/9] END dropout=0.05, learning_rate=0.01;, score=0.847 total time=   6.5s\n",
      "[CV 1/3; 6/9] START dropout=0.05, learning_rate=0.1.............................\n",
      "[CV 1/3; 6/9] END dropout=0.05, learning_rate=0.1;, score=0.695 total time=   6.7s\n",
      "[CV 2/3; 6/9] START dropout=0.05, learning_rate=0.1.............................\n",
      "[CV 2/3; 6/9] END dropout=0.05, learning_rate=0.1;, score=0.771 total time=   6.6s\n",
      "[CV 3/3; 6/9] START dropout=0.05, learning_rate=0.1.............................\n",
      "[CV 3/3; 6/9] END dropout=0.05, learning_rate=0.1;, score=0.702 total time=   6.0s\n",
      "[CV 1/3; 7/9] START dropout=0.1, learning_rate=0.001............................\n",
      "[CV 1/3; 7/9] END dropout=0.1, learning_rate=0.001;, score=0.733 total time=   6.8s\n",
      "[CV 2/3; 7/9] START dropout=0.1, learning_rate=0.001............................\n",
      "[CV 2/3; 7/9] END dropout=0.1, learning_rate=0.001;, score=0.771 total time=   5.3s\n",
      "[CV 3/3; 7/9] START dropout=0.1, learning_rate=0.001............................\n",
      "[CV 3/3; 7/9] END dropout=0.1, learning_rate=0.001;, score=0.847 total time=   5.0s\n",
      "[CV 1/3; 8/9] START dropout=0.1, learning_rate=0.01.............................\n",
      "[CV 1/3; 8/9] END dropout=0.1, learning_rate=0.01;, score=0.725 total time=   5.9s\n",
      "[CV 2/3; 8/9] START dropout=0.1, learning_rate=0.01.............................\n",
      "[CV 2/3; 8/9] END dropout=0.1, learning_rate=0.01;, score=0.756 total time=   4.9s\n",
      "[CV 3/3; 8/9] START dropout=0.1, learning_rate=0.01.............................\n",
      "[CV 3/3; 8/9] END dropout=0.1, learning_rate=0.01;, score=0.832 total time=   4.7s\n",
      "[CV 1/3; 9/9] START dropout=0.1, learning_rate=0.1..............................\n",
      "[CV 1/3; 9/9] END dropout=0.1, learning_rate=0.1;, score=0.733 total time=   4.9s\n",
      "[CV 2/3; 9/9] START dropout=0.1, learning_rate=0.1..............................\n",
      "[CV 2/3; 9/9] END dropout=0.1, learning_rate=0.1;, score=0.771 total time=   4.2s\n",
      "[CV 3/3; 9/9] START dropout=0.1, learning_rate=0.1..............................\n",
      "[CV 3/3; 9/9] END dropout=0.1, learning_rate=0.1;, score=0.725 total time=   5.1s\n",
      "Best: 0.7888040741284689, using {'dropout': 0, 'learning_rate': 0.001}\n",
      "Mean: 0.7888040741284689, Standard Deviation: 0.04678058542777775, using {'dropout': 0, 'learning_rate': 0.001}\n",
      "Mean: 0.7557251850763956, Standard Deviation: 0.03470275778092071, using {'dropout': 0, 'learning_rate': 0.01}\n",
      "Mean: 0.7150127092997233, Standard Deviation: 0.009520757155231074, using {'dropout': 0, 'learning_rate': 0.1}\n",
      "Mean: 0.7888040542602539, Standard Deviation: 0.03074566361563103, using {'dropout': 0.05, 'learning_rate': 0.001}\n",
      "Mean: 0.7888040741284689, Standard Deviation: 0.04421920515449277, using {'dropout': 0.05, 'learning_rate': 0.01}\n",
      "Mean: 0.7226462960243225, Standard Deviation: 0.03432756632257055, using {'dropout': 0.05, 'learning_rate': 0.1}\n",
      "Mean: 0.783715009689331, Standard Deviation: 0.04760378046613292, using {'dropout': 0.1, 'learning_rate': 0.001}\n",
      "Mean: 0.7709923585255941, Standard Deviation: 0.04494534616862407, using {'dropout': 0.1, 'learning_rate': 0.01}\n",
      "Mean: 0.7430025339126587, Standard Deviation: 0.02003563393011416, using {'dropout': 0.1, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Here we will grid search over activtion and kernel_initializer \r\n",
    "\r\n",
    "# Define our model\r\n",
    "def create_model(activation, init):\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer=init, activation = activation))\r\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer=init, activation = activation))\r\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\r\n",
    "    \r\n",
    "    # Compile the model\r\n",
    "    adam = Adam(learning_rate=0.001)\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "\r\n",
    "# Create a model\r\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=10, epochs=100, verbose = 0)\r\n",
    "\r\n",
    "# Grid Search over activation and kernel_initializer \r\n",
    "activation = ['softmax', 'linear', 'relu', 'tanh']\r\n",
    "init = ['uniform', 'normal', 'zero']\r\n",
    "\r\n",
    "# Make a dictionary for grid search parameters as GridSearchCV takes dictionary as inputs \r\n",
    "param_grid = dict(activation=activation, init=init)\r\n",
    "\r\n",
    "# Build and fit over grid parameters\r\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(n_splits=3), verbose=10)\r\n",
    "grid_results = grid.fit(X_standardized, Y)\r\n",
    "\r\n",
    "# Summarize the result \r\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\r\n",
    "\r\n",
    "means = grid_results.cv_results_['mean_test_score']\r\n",
    "stds = grid_results.cv_results_['std_test_score']\r\n",
    "params = grid_results.cv_results_['params']\r\n",
    "\r\n",
    "for mean, std, param in zip(means, stds, params):\r\n",
    "    print(\"Mean: {0}, Standard Deviation: {1}, using {2}\".format(mean, std, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV 1/3; 1/12] START activation=softmax, init=uniform...........................\n",
      "[CV 1/3; 1/12] END activation=softmax, init=uniform;, score=0.718 total time=   5.9s\n",
      "[CV 2/3; 1/12] START activation=softmax, init=uniform...........................\n",
      "[CV 2/3; 1/12] END activation=softmax, init=uniform;, score=0.771 total time=   5.5s\n",
      "[CV 3/3; 1/12] START activation=softmax, init=uniform...........................\n",
      "[CV 3/3; 1/12] END activation=softmax, init=uniform;, score=0.809 total time=   5.0s\n",
      "[CV 1/3; 2/12] START activation=softmax, init=normal............................\n",
      "[CV 1/3; 2/12] END activation=softmax, init=normal;, score=0.725 total time=   5.9s\n",
      "[CV 2/3; 2/12] START activation=softmax, init=normal............................\n",
      "[CV 2/3; 2/12] END activation=softmax, init=normal;, score=0.756 total time=   5.2s\n",
      "[CV 3/3; 2/12] START activation=softmax, init=normal............................\n",
      "[CV 3/3; 2/12] END activation=softmax, init=normal;, score=0.824 total time=   4.2s\n",
      "[CV 1/3; 3/12] START activation=softmax, init=zero..............................\n",
      "[CV 1/3; 3/12] END activation=softmax, init=zero;, score=0.611 total time=   5.3s\n",
      "[CV 2/3; 3/12] START activation=softmax, init=zero..............................\n",
      "[CV 2/3; 3/12] END activation=softmax, init=zero;, score=0.695 total time=   4.8s\n",
      "[CV 3/3; 3/12] START activation=softmax, init=zero..............................\n",
      "[CV 3/3; 3/12] END activation=softmax, init=zero;, score=0.702 total time=   6.0s\n",
      "[CV 1/3; 4/12] START activation=linear, init=uniform............................\n",
      "[CV 1/3; 4/12] END activation=linear, init=uniform;, score=0.771 total time=   5.3s\n",
      "[CV 2/3; 4/12] START activation=linear, init=uniform............................\n",
      "[CV 2/3; 4/12] END activation=linear, init=uniform;, score=0.763 total time=   5.0s\n",
      "[CV 3/3; 4/12] START activation=linear, init=uniform............................\n",
      "[CV 3/3; 4/12] END activation=linear, init=uniform;, score=0.840 total time=   4.8s\n",
      "[CV 1/3; 5/12] START activation=linear, init=normal.............................\n",
      "[CV 1/3; 5/12] END activation=linear, init=normal;, score=0.771 total time=   5.0s\n",
      "[CV 2/3; 5/12] START activation=linear, init=normal.............................\n",
      "[CV 2/3; 5/12] END activation=linear, init=normal;, score=0.763 total time=   4.5s\n",
      "[CV 3/3; 5/12] START activation=linear, init=normal.............................\n",
      "[CV 3/3; 5/12] END activation=linear, init=normal;, score=0.832 total time=   5.1s\n",
      "[CV 1/3; 6/12] START activation=linear, init=zero...............................\n",
      "[CV 1/3; 6/12] END activation=linear, init=zero;, score=0.611 total time=   4.3s\n",
      "[CV 2/3; 6/12] START activation=linear, init=zero...............................\n",
      "[CV 2/3; 6/12] END activation=linear, init=zero;, score=0.695 total time=   4.6s\n",
      "[CV 3/3; 6/12] START activation=linear, init=zero...............................\n",
      "[CV 3/3; 6/12] END activation=linear, init=zero;, score=0.702 total time=   5.9s\n",
      "[CV 1/3; 7/12] START activation=relu, init=uniform..............................\n",
      "[CV 1/3; 7/12] END activation=relu, init=uniform;, score=0.725 total time=   5.3s\n",
      "[CV 2/3; 7/12] START activation=relu, init=uniform..............................\n",
      "[CV 2/3; 7/12] END activation=relu, init=uniform;, score=0.748 total time=   4.9s\n",
      "[CV 3/3; 7/12] START activation=relu, init=uniform..............................\n",
      "[CV 3/3; 7/12] END activation=relu, init=uniform;, score=0.824 total time=   5.1s\n",
      "[CV 1/3; 8/12] START activation=relu, init=normal...............................\n",
      "[CV 1/3; 8/12] END activation=relu, init=normal;, score=0.763 total time=   5.0s\n",
      "[CV 2/3; 8/12] START activation=relu, init=normal...............................\n",
      "[CV 2/3; 8/12] END activation=relu, init=normal;, score=0.779 total time=   4.7s\n",
      "[CV 3/3; 8/12] START activation=relu, init=normal...............................\n",
      "[CV 3/3; 8/12] END activation=relu, init=normal;, score=0.832 total time=   5.0s\n",
      "[CV 1/3; 9/12] START activation=relu, init=zero.................................\n",
      "[CV 1/3; 9/12] END ..activation=relu, init=zero;, score=0.611 total time=   5.0s\n",
      "[CV 2/3; 9/12] START activation=relu, init=zero.................................\n",
      "[CV 2/3; 9/12] END ..activation=relu, init=zero;, score=0.695 total time=   4.6s\n",
      "[CV 3/3; 9/12] START activation=relu, init=zero.................................\n",
      "[CV 3/3; 9/12] END ..activation=relu, init=zero;, score=0.702 total time=   5.8s\n",
      "[CV 1/3; 10/12] START activation=tanh, init=uniform.............................\n",
      "[CV 1/3; 10/12] END activation=tanh, init=uniform;, score=0.748 total time=   5.0s\n",
      "[CV 2/3; 10/12] START activation=tanh, init=uniform.............................\n",
      "[CV 2/3; 10/12] END activation=tanh, init=uniform;, score=0.771 total time=   4.9s\n",
      "[CV 3/3; 10/12] START activation=tanh, init=uniform.............................\n",
      "[CV 3/3; 10/12] END activation=tanh, init=uniform;, score=0.832 total time=   6.1s\n",
      "[CV 1/3; 11/12] START activation=tanh, init=normal..............................\n",
      "[CV 1/3; 11/12] END activation=tanh, init=normal;, score=0.748 total time=   6.5s\n",
      "[CV 2/3; 11/12] START activation=tanh, init=normal..............................\n",
      "[CV 2/3; 11/12] END activation=tanh, init=normal;, score=0.771 total time=   4.7s\n",
      "[CV 3/3; 11/12] START activation=tanh, init=normal..............................\n",
      "[CV 3/3; 11/12] END activation=tanh, init=normal;, score=0.832 total time=   4.7s\n",
      "[CV 1/3; 12/12] START activation=tanh, init=zero................................\n",
      "[CV 1/3; 12/12] END .activation=tanh, init=zero;, score=0.611 total time=   4.8s\n",
      "[CV 2/3; 12/12] START activation=tanh, init=zero................................\n",
      "[CV 2/3; 12/12] END .activation=tanh, init=zero;, score=0.695 total time=   5.1s\n",
      "[CV 3/3; 12/12] START activation=tanh, init=zero................................\n",
      "[CV 3/3; 12/12] END .activation=tanh, init=zero;, score=0.702 total time=   4.8s\n",
      "Best: 0.7913485964139303, using {'activation': 'linear', 'init': 'uniform'}\n",
      "Mean: 0.7659032940864563, Standard Deviation: 0.037569518204122236, using {'activation': 'softmax', 'init': 'uniform'}\n",
      "Mean: 0.7684478362401327, Standard Deviation: 0.0415000243966187, using {'activation': 'softmax', 'init': 'normal'}\n",
      "Mean: 0.669211188952128, Standard Deviation: 0.04150001465103028, using {'activation': 'softmax', 'init': 'zero'}\n",
      "Mean: 0.7913485964139303, Standard Deviation: 0.03432759430444261, using {'activation': 'linear', 'init': 'uniform'}\n",
      "Mean: 0.7888040542602539, Standard Deviation: 0.03074566361563103, using {'activation': 'linear', 'init': 'normal'}\n",
      "Mean: 0.669211188952128, Standard Deviation: 0.04150001465103028, using {'activation': 'linear', 'init': 'zero'}\n",
      "Mean: 0.7659032940864563, Standard Deviation: 0.042425793542818904, using {'activation': 'relu', 'init': 'uniform'}\n",
      "Mean: 0.7913485964139303, Standard Deviation: 0.029455048775169097, using {'activation': 'relu', 'init': 'normal'}\n",
      "Mean: 0.669211188952128, Standard Deviation: 0.04150001465103028, using {'activation': 'relu', 'init': 'zero'}\n",
      "Mean: 0.7837149898211161, Standard Deviation: 0.03544119565013847, using {'activation': 'tanh', 'init': 'uniform'}\n",
      "Mean: 0.7837149898211161, Standard Deviation: 0.03544119565013847, using {'activation': 'tanh', 'init': 'normal'}\n",
      "Mean: 0.669211188952128, Standard Deviation: 0.04150001465103028, using {'activation': 'tanh', 'init': 'zero'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# NOTE that Activation: 'relu' and init: 'normal' even acheives the best accuracy, so we will use it. \r\n",
    "# Here we will grid search over no. of hidden units\r\n",
    "\r\n",
    "# Define our model\r\n",
    "def create_model(neuron1, neuron2):\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(neuron1, input_dim = 8, kernel_initializer='normal', activation = 'relu'))\r\n",
    "    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer='normal', activation = 'relu'))\r\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\r\n",
    "    \r\n",
    "    # Compile the model\r\n",
    "    adam = Adam(learning_rate=0.001)\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "\r\n",
    "# Create a model\r\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=10, epochs=100, verbose = 0)\r\n",
    "\r\n",
    "# Grid Search over no. of hidden units\r\n",
    "neuron1 = [4, 8, 16]\r\n",
    "neuron2 = [2, 4, 8] \r\n",
    "\r\n",
    "# Make a dictionary for grid search parameters as GridSearchCV takes dictionary as inputs \r\n",
    "param_grid = dict(neuron1=neuron1, neuron2=neuron2)\r\n",
    "\r\n",
    "# Build and fit over grid parameters\r\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(n_splits=3), refit=True, verbose=10)\r\n",
    "grid_results = grid.fit(X_standardized, Y)\r\n",
    "\r\n",
    "# Summarize the result \r\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\r\n",
    "\r\n",
    "means = grid_results.cv_results_['mean_test_score']\r\n",
    "stds = grid_results.cv_results_['std_test_score']\r\n",
    "params = grid_results.cv_results_['params']\r\n",
    "\r\n",
    "for mean, std, param in zip(means, stds, params):\r\n",
    "    print(\"Mean: {0}, Standard Deviation: {1}, using {2}\".format(mean, std, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV 1/3; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/3; 1/9] END .........neuron1=4, neuron2=2;, score=0.771 total time=   5.3s\n",
      "[CV 2/3; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/3; 1/9] END .........neuron1=4, neuron2=2;, score=0.771 total time=   5.7s\n",
      "[CV 3/3; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/3; 1/9] END .........neuron1=4, neuron2=2;, score=0.832 total time=   5.4s\n",
      "[CV 1/3; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/3; 2/9] END .........neuron1=4, neuron2=4;, score=0.748 total time=   5.6s\n",
      "[CV 2/3; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/3; 2/9] END .........neuron1=4, neuron2=4;, score=0.779 total time=   5.5s\n",
      "[CV 3/3; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/3; 2/9] END .........neuron1=4, neuron2=4;, score=0.863 total time=   5.3s\n",
      "[CV 1/3; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/3; 3/9] END .........neuron1=4, neuron2=8;, score=0.740 total time=   5.9s\n",
      "[CV 2/3; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/3; 3/9] END .........neuron1=4, neuron2=8;, score=0.771 total time=   5.6s\n",
      "[CV 3/3; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/3; 3/9] END .........neuron1=4, neuron2=8;, score=0.802 total time=   6.1s\n",
      "[CV 1/3; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/3; 4/9] END .........neuron1=8, neuron2=2;, score=0.733 total time=   5.2s\n",
      "[CV 2/3; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/3; 4/9] END .........neuron1=8, neuron2=2;, score=0.756 total time=   4.7s\n",
      "[CV 3/3; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/3; 4/9] END .........neuron1=8, neuron2=2;, score=0.809 total time=   5.9s\n",
      "[CV 1/3; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/3; 5/9] END .........neuron1=8, neuron2=4;, score=0.733 total time=   6.0s\n",
      "[CV 2/3; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/3; 5/9] END .........neuron1=8, neuron2=4;, score=0.756 total time=   6.0s\n",
      "[CV 3/3; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/3; 5/9] END .........neuron1=8, neuron2=4;, score=0.809 total time=   5.1s\n",
      "[CV 1/3; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/3; 6/9] END .........neuron1=8, neuron2=8;, score=0.740 total time=   4.8s\n",
      "[CV 2/3; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/3; 6/9] END .........neuron1=8, neuron2=8;, score=0.771 total time=   4.5s\n",
      "[CV 3/3; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/3; 6/9] END .........neuron1=8, neuron2=8;, score=0.847 total time=   5.0s\n",
      "[CV 1/3; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/3; 7/9] END ........neuron1=16, neuron2=2;, score=0.733 total time=   5.3s\n",
      "[CV 2/3; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/3; 7/9] END ........neuron1=16, neuron2=2;, score=0.733 total time=   5.3s\n",
      "[CV 3/3; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/3; 7/9] END ........neuron1=16, neuron2=2;, score=0.832 total time=   5.5s\n",
      "[CV 1/3; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/3; 8/9] END ........neuron1=16, neuron2=4;, score=0.771 total time=   5.4s\n",
      "[CV 2/3; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/3; 8/9] END ........neuron1=16, neuron2=4;, score=0.756 total time=   5.3s\n",
      "[CV 3/3; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/3; 8/9] END ........neuron1=16, neuron2=4;, score=0.847 total time=   5.2s\n",
      "[CV 1/3; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/3; 9/9] END ........neuron1=16, neuron2=8;, score=0.740 total time=   7.0s\n",
      "[CV 2/3; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/3; 9/9] END ........neuron1=16, neuron2=8;, score=0.748 total time=   5.1s\n",
      "[CV 3/3; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/3; 9/9] END ........neuron1=16, neuron2=8;, score=0.832 total time=   5.4s\n",
      "Best: 0.796437660853068, using {'neuron1': 4, 'neuron2': 4}\n",
      "Mean: 0.7913485765457153, Standard Deviation: 0.028788067700578082, using {'neuron1': 4, 'neuron2': 2}\n",
      "Mean: 0.796437660853068, Standard Deviation: 0.04841298651222533, using {'neuron1': 4, 'neuron2': 4}\n",
      "Mean: 0.7709923585255941, Standard Deviation: 0.024931197954570848, using {'neuron1': 4, 'neuron2': 8}\n",
      "Mean: 0.7659033139546713, Standard Deviation: 0.03198422346497647, using {'neuron1': 8, 'neuron2': 2}\n",
      "Mean: 0.7659033139546713, Standard Deviation: 0.03198422346497647, using {'neuron1': 8, 'neuron2': 4}\n",
      "Mean: 0.7862595319747925, Standard Deviation: 0.04494535291751992, using {'neuron1': 8, 'neuron2': 8}\n",
      "Mean: 0.7659033139546713, Standard Deviation: 0.04678058542777775, using {'neuron1': 16, 'neuron2': 2}\n",
      "Mean: 0.7913485964139303, Standard Deviation: 0.04007128804634343, using {'neuron1': 16, 'neuron2': 4}\n",
      "Mean: 0.7735368808110555, Standard Deviation: 0.04150001465103028, using {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Generating predictions on optimal hyperparameters \r\n",
    "# ( We can do this as we set refit=True in the grid above, so grid is retraained with optaimal parameters)\r\n",
    "y_pred = grid.predict(X_standardized)\r\n",
    "\r\n",
    "print(y_pred.shape)\r\n",
    "print(y_pred[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\91773\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(393, 1)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\r\n",
    "\r\n",
    "print(accuracy_score(Y, y_pred))\r\n",
    "print(classification_report(Y, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.816793893129771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       263\n",
      "           1       0.73      0.72      0.72       130\n",
      "\n",
      "    accuracy                           0.82       393\n",
      "   macro avg       0.79      0.79      0.79       393\n",
      "weighted avg       0.82      0.82      0.82       393\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Predict on example data \r\n",
    "example = df.iloc[1] \r\n",
    "print(example)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_pregnant                   0.000\n",
      "glucose_concentration      137.000\n",
      "blood_pressuer (mm Hg)      40.000\n",
      "skin_thickness (mm)         35.000\n",
      "serum_insulin (mu U/ml)    168.000\n",
      "BMI                         43.100\n",
      "pedigree_function            2.288\n",
      "age                         33.000\n",
      "class                        1.000\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Predict using our deep neural network model \r\n",
    "prediction = grid.predict(X_standardized[1].reshape(1,-1))\r\n",
    "print(prediction)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1]]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\91773\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving model in the file "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from tensorflow.keras.layers import Dropout\r\n",
    "\r\n",
    "# Creating the model with all optimal hyperparameters \r\n",
    "def create_model():\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation = 'relu'))\r\n",
    "    model.add(Dense(4, input_dim = 4, kernel_initializer='normal', activation = 'relu'))\r\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\r\n",
    "    \r\n",
    "    # Compile the model\r\n",
    "    adam = Adam(learning_rate=0.001)\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "\r\n",
    "# Create the model \r\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=10,epochs=100, verbose = 0)\r\n",
    "history = model.fit(X_standardized, Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "loss = history.history['loss']\r\n",
    "acc = history.history['accuracy']\r\n",
    "\r\n",
    "plt.figure(figsize=(15,5))\r\n",
    "plt.subplot(1,2,1)\r\n",
    "plt.plot(acc)\r\n",
    "plt.title('model accuracy')\r\n",
    "plt.xlabel('epochs')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "\r\n",
    "plt.subplot(1,2,2)\r\n",
    "plt.plot(loss)\r\n",
    "plt.title('Loss Function')\r\n",
    "plt.xlabel('epochs')\r\n",
    "plt.ylabel('Loss')\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Checking if model is correctly made \r\n",
    "from sklearn.metrics import classification_report, accuracy_score\r\n",
    "\r\n",
    "y_pred = model.predict(X_standardized)\r\n",
    "\r\n",
    "print(accuracy_score(Y, y_pred))\r\n",
    "print(classification_report(Y, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\91773\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8244274809160306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       263\n",
      "           1       0.75      0.70      0.73       130\n",
      "\n",
      "    accuracy                           0.82       393\n",
      "   macro avg       0.80      0.79      0.80       393\n",
      "weighted avg       0.82      0.82      0.82       393\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Saving the model, without making the pipeline \r\n",
    "import pickle \r\n",
    "model.model.save('neural_network_model.h5')   \r\n",
    "# We have saved the model not keras Classifier, the model will gave us values in range [0,1] and not discrete values  \r\n",
    "\r\n",
    "pickle.dump(scaler, open('Scaler.pkl', 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Loading the model and making a pipeline \r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from tensorflow.keras.models import load_model \r\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "\r\n",
    "scale = pickle.load(open('Scaler.pkl', 'rb'))\r\n",
    "loaded_model = load_model('neural_network_model.h5')\r\n",
    "\r\n",
    "pipe = Pipeline([('scaler', scale), ('Neural-network', loaded_model )])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Verifying that pipeline works accurately \r\n",
    "\r\n",
    "# Use some random training data for checking \r\n",
    "ex = df.iloc[7].values[:-1]\r\n",
    "ex = ex.reshape(1,-1)\r\n",
    "print(df.iloc[7]['class'])\r\n",
    "\r\n",
    "# Predict using pipeline \r\n",
    "prediction = pipe.predict(ex)\r\n",
    "prediction = prediction.item() \r\n",
    "print(round(prediction))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}